<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Meet Agarwal | AI Voice Interface</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #0E1117 0%, #1a1a2e 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            padding: 20px;
        }

        .container {
            width: 100%;
            max-width: 600px;
        }

        .orb-section {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 40px;
            margin-bottom: 40px;
        }

        .orb {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background: radial-gradient(circle at 30% 30%, #4facfe, #00f2fe);
            box-shadow: 0 0 30px #00f2fe, 0 0 60px #4facfe;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 70px;
            animation: pulse 2s infinite ease-in-out;
            flex-shrink: 0;
        }

        .orb.listening {
            animation: pulse 2s infinite ease-in-out;
            background: radial-gradient(circle at 30% 30%, #4facfe, #00f2fe);
            box-shadow: 0 0 30px #00f2fe, 0 0 60px #4facfe;
        }

        .orb.processing {
            animation: pulse 1s infinite ease-in-out;
            background: radial-gradient(circle at 30% 30%, #fbbf24, #f59e0b);
            box-shadow: 0 0 30px #f59e0b, 0 0 60px #fbbf24;
        }

        .orb.speaking {
            animation: pulse 0.7s infinite ease-in-out;
            background: radial-gradient(circle at 30% 30%, #ff6b9d, #c2185b);
            box-shadow: 0 0 40px #ff6b9d, 0 0 80px #ff6b9d;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.12); }
        }

        .greeting {
            text-align: left;
        }

        .greeting h1 {
            font-size: 32px;
            font-weight: 400;
            margin-bottom: 5px;
        }

        .greeting h1 .name {
            color: #4facfe;
            font-weight: 700;
        }

        .greeting p {
            font-size: 16px;
            color: #999;
        }

        .status-box {
            background-color: rgba(79, 172, 254, 0.12);
            border-left: 4px solid #4facfe;
            padding: 20px;
            border-radius: 12px;
            text-align: center;
            font-size: 18px;
            margin-bottom: 20px;
            min-height: 70px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .conversation-box {
            background-color: rgba(30, 30, 46, 0.8);
            border: 1px solid rgba(79, 172, 254, 0.2);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
            max-height: 400px;
            overflow-y: auto;
            scroll-behavior: smooth;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 16px;
            border-radius: 8px;
            line-height: 1.5;
            word-wrap: break-word;
        }

        .message.user {
            background-color: rgba(79, 172, 254, 0.15);
            border-left: 4px solid #4facfe;
        }

        .message.ai {
            background-color: rgba(255, 107, 157, 0.12);
            border-left: 4px solid #ff6b9d;
        }

        .message-label {
            font-weight: 600;
            margin-bottom: 5px;
            font-size: 14px;
        }

        .message.user .message-label {
            color: #4facfe;
        }

        .message.ai .message-label {
            color: #ff6b9d;
        }

        .message-text {
            color: #E0E0E0;
            font-size: 15px;
        }

        .mic-section {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }

        .mic-button {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            background: #4facfe;
            color: white;
            font-size: 40px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(79, 172, 254, 0.3);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .mic-button:hover:not(:disabled) {
            background: #00d4ff;
            transform: scale(1.1);
            box-shadow: 0 4px 25px rgba(79, 172, 254, 0.5);
        }

        .mic-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .mic-button.listening {
            animation: mic-pulse 1s infinite;
            background: #4facfe;
        }

        .mic-button.processing {
            background: #fbbf24;
        }

        .mic-button.speaking {
            background: #ff6b9d;
            animation: mic-pulse 0.7s infinite;
        }

        @keyframes mic-pulse {
            0%, 100% { box-shadow: 0 4px 15px rgba(79, 172, 254, 0.3); }
            50% { box-shadow: 0 4px 25px rgba(79, 172, 254, 0.8); }
        }

        .info-text {
            text-align: center;
            color: #666;
            font-size: 12px;
            margin-top: 20px;
        }

        ::-webkit-scrollbar {
            width: 6px;
        }

        ::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
        }

        ::-webkit-scrollbar-thumb {
            background: rgba(79, 172, 254, 0.3);
            border-radius: 10px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: rgba(79, 172, 254, 0.5);
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Orb & Greeting -->
        <div class="orb-section">
            <div class="orb listening" id="orb">ü§ñ</div>
            <div class="greeting">
                <h1>Hi, I'm <span class="name">Meet</span></h1>
                <p>AI Engineer</p>
            </div>
        </div>

        <!-- Status -->
        <div class="status-box" id="status">üé§ Ready to listen...</div>

        <!-- Conversation -->
        <div class="conversation-box" id="conversation">
            <div class="message ai">
                <div class="message-label">Meet:</div>
                <div class="message-text">Hi, nice to meet you! I'm Meet Agarwal, an AI Engineer at PluginHive. Feel free to ask me anything about my experience or projects!</div>
            </div>
        </div>

        <!-- Mic Button -->
        <div class="mic-section">
            <button class="mic-button listening" id="micButton">üé§</button>
        </div>

        <div class="info-text">
            Click the mic to start ‚Ä¢ Natural conversation flow ‚Ä¢ No manual clicks needed
        </div>
    </div>

    <!-- Hidden audio element -->
    <audio id="audioPlayer" style="display:none;"></audio>

    <script>
        // Constants
        const GROQ_API_KEY = 'YOUR_GROQ_API_KEY_HERE'; // Replace with actual key
        const SYSTEM_CONTEXT = `You are Meet Agarwal, an AI Engineer currently working at PluginHive. You are in a behavioral interview. You speak clearly, concisely, and confidently.

YOUR PROFILE:

Current Role: AI Engineer at PluginHive (May 2025 - Present).

Architected a Retrieval-Augmented Generation (RAG) chatbot that handles high volume of daily customer queries using LangChain and GPT-4.

Built a high-performance semantic search pipeline by leveraging AWS OpenSearch for vector indexing.

Reduced customer friction and repeat queries by engineering a persistent chat history storage solution on AWS S3.

Key Projects:

Plant Disease Detection: Developed and deployed a CNN-based model on Streamlit, achieving 92% accuracy in real-world conditions.

AI Cold Email Generator: Created an end-to-end system using LangChain and Groq to automate job scraping and personalized email composition.

Automated Face Recognition Attendance: Implemented a production-ready attendance solution using OpenCV and custom algorithms.

Core Tech Stack: Deep expertise in Python, LangChain, RAG, and production deployment (Docker, CI/CD). Proficient in AWS services (S3, SSM) and Vector Databases (Chroma, FAISS).

TONE GUIDELINES: Keep answers short (2-3 sentences max) to mimic real voice conversation. Be humble but impressive. Use numbers to back up claims.`;

        // State
        let state = 'listening'; // listening, processing, speaking
        let mediaRecorder;
        let audioChunks = [];

        // DOM Elements
        const orb = document.getElementById('orb');
        const status = document.getElementById('status');
        const micButton = document.getElementById('micButton');
        const conversation = document.getElementById('conversation');
        const audioPlayer = document.getElementById('audioPlayer');

        // Update UI based on state
        function updateUI(newState) {
            state = newState;
            orb.className = `orb ${state}`;
            micButton.className = `mic-button ${state}`;
            micButton.disabled = state !== 'listening';

            switch(state) {
                case 'listening':
                    status.textContent = 'üé§ Ready to listen...';
                    break;
                case 'processing':
                    status.textContent = '‚è≥ Processing...';
                    break;
                case 'speaking':
                    status.textContent = 'üîä Speaking...';
                    break;
            }
        }

        // Add message to conversation
        function addMessage(role, text) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            messageDiv.innerHTML = `
                <div class="message-label">${role === 'user' ? 'You' : 'Meet'}:</div>
                <div class="message-text">${escapeHtml(text)}</div>
            `;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        // Escape HTML
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        // Initialize speech recognition
        function initSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (!SpeechRecognition) {
                alert('Speech Recognition not supported in your browser');
                return null;
            }

            const recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                updateUI('processing');
                status.textContent = 'üéß Listening...';
            };

            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }

                if (finalTranscript) {
                    handleUserMessage(finalTranscript.trim());
                } else if (interimTranscript) {
                    status.textContent = `üéß Heard: "${interimTranscript}"`;
                }
            };

            recognition.onerror = () => {
                updateUI('listening');
                status.textContent = '‚ùå Listening error. Try again.';
            };

            recognition.onend = () => {
                // Don't update UI here - let handleUserMessage do it
            };

            return recognition;
        }

        const recognition = initSpeechRecognition();

        // Handle user message
        async function handleUserMessage(userText) {
            if (!userText.trim()) {
                updateUI('listening');
                return;
            }

            // Add user message to conversation
            addMessage('user', userText);
            updateUI('processing');

            try {
                // Get AI response
                const aiResponse = await getAIResponse(userText);
                
                // Add AI message to conversation
                addMessage('ai', aiResponse);
                
                // Speak response
                await speakResponse(aiResponse);
                
                // Back to listening
                updateUI('listening');
                
                // Auto-start listening after 1 second
                setTimeout(() => {
                    if (recognition) {
                        recognition.start();
                    }
                }, 1000);

            } catch (error) {
                console.error('Error:', error);
                updateUI('listening');
                status.textContent = '‚ö†Ô∏è Error processing. Try again.';
            }
        }

        // Get AI response from backend
        async function getAIResponse(userMessage) {
            try {
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        message: userMessage
                    })
                });

                const data = await response.json();
                
                if (data.success) {
                    return data.response;
                } else {
                    throw new Error(data.error || 'Unknown error');
                }
            } catch (error) {
                console.error('Error getting AI response:', error);
                return "I apologize, I'm having trouble processing that. Could you please repeat?";
            }
        }

        // Speak response using Web Speech API
        async function speakResponse(text) {
            return new Promise((resolve) => {
                updateUI('speaking');
                status.textContent = 'üîä Speaking...';

                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                utterance.volume = 1.0;

                utterance.onend = () => {
                    resolve();
                };

                utterance.onerror = () => {
                    console.error('Speech synthesis error');
                    resolve();
                };

                speechSynthesis.cancel();
                speechSynthesis.speak(utterance);
            });
        }

        // Mic button click
        micButton.addEventListener('click', () => {
            if (recognition && state === 'listening') {
                recognition.start();
            }
        });

        // Start with greeting
        window.addEventListener('load', () => {
            updateUI('listening');
        });
    </script>
</body>
</html>